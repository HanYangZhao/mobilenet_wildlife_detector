{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wildlife_transfer_learning_ssd_mobilnets2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtzbD7bGIZYF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGf68jtDp-kW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install numpy==1.16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xe0B5UXuhZWa",
        "colab_type": "text"
      },
      "source": [
        "For the code cell below you should see ‘Found GPU’ and tf version 1.x. Else remember to change runtime to GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5blGTazUTft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zmVdivOVW8x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install protobuf-compiler python-pil python-lxml python-tk\n",
        "!pip install Cython"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2mRk4Mbiwgs",
        "colab_type": "text"
      },
      "source": [
        "Clome the Tensorflow API repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVZekwLaVXEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/tensorflow/models.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dro4CRIRi72C",
        "colab_type": "text"
      },
      "source": [
        "Install some needed tools and dependencies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgshHq3dVW2J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/models/research/\n",
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMlRrzpVVWys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQlUBRt2i-z8",
        "colab_type": "text"
      },
      "source": [
        "Always run the cell below for every session restart"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSTazdeuVWb0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python setup.py build\n",
        "!python setup.py install"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0SboZDxjHea",
        "colab_type": "text"
      },
      "source": [
        "Check thr remaining time allowed for the session you are runing. Depending on your data try to know the number of hours that will be enough. If the time is lesser then restart the session. NB the time result you see in in hours"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifNU3ISjYrSj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time, psutil\n",
        "Start = time.time()- psutil.boot_time()\n",
        "Left= 12*3600 - Start\n",
        "print('Time remaining for this session is: ', Left/3600)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyVoEWI_juSr",
        "colab_type": "text"
      },
      "source": [
        "Run Code below to see if all we need for the training has been installed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q20GGC2ibcLW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#rember the last CD you did in order to specify the directory.\n",
        "!pip install git+https://github.com/google-research/tf-slim.git\n",
        "%cd /content/models/research/object_detection/builders/\n",
        "!python model_builder_test.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gxb4WS0j70_",
        "colab_type": "text"
      },
      "source": [
        "Change Directory to object detection folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvnplLY3pdfA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/models/research/object_detection/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stRXlkcZkuRr",
        "colab_type": "text"
      },
      "source": [
        "Get the pre-trained Object detection model from TensorFlow with the code below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxcToVgeoapI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz\n",
        "!tar -xvf ssd_mobilenet_v2_coco_2018_03_29.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7weIPNPIp63",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install tensorboardcolab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzKZ-e-smUtE",
        "colab_type": "text"
      },
      "source": [
        "Ensure to run the code cell below first"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whn-YfyYKtJK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-FFYE0XmfgM",
        "colab_type": "text"
      },
      "source": [
        "IF you want to keep track of your model loss it best to run tensor board in background just like this before you run your training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwmM54OdJLRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir training/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MPAWDyumBTa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LOG_DIR = '/tmp/log'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "\n",
        "! wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "! unzip ngrok-stable-linux-amd64.zip\n",
        "\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLhEp17jm8oi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open ('ssd_mobilenet_v2_coco.config', 'w') as rsh:\n",
        "    rsh.write('''\\\n",
        "    # Quantized trained SSD with Mobilenet v2 on Pascal VOC Dataset.\n",
        "    model {\n",
        "      ssd {\n",
        "        num_classes: 15\n",
        "        image_resizer {\n",
        "          fixed_shape_resizer {\n",
        "            height: 300\n",
        "            width: 300\n",
        "          }\n",
        "        }\n",
        "        feature_extractor {\n",
        "          type: \"ssd_mobilenet_v2\"\n",
        "          depth_multiplier: 1.0\n",
        "          min_depth: 16\n",
        "          conv_hyperparams {\n",
        "            regularizer {\n",
        "              l2_regularizer {\n",
        "                weight: 3.99999989895e-05\n",
        "              }\n",
        "            }\n",
        "            initializer {\n",
        "              random_normal_initializer {\n",
        "                mean: 0.0\n",
        "                stddev: 0.00999999977648\n",
        "              }\n",
        "            }\n",
        "            activation: RELU_6\n",
        "            batch_norm {\n",
        "              decay: 0.97000002861\n",
        "              center: true\n",
        "              scale: true\n",
        "              epsilon: 0.0010000000475\n",
        "            }\n",
        "          }\n",
        "          override_base_feature_extractor_hyperparams: true\n",
        "        }\n",
        "        box_coder {\n",
        "          faster_rcnn_box_coder {\n",
        "            y_scale: 10.0\n",
        "            x_scale: 10.0\n",
        "            height_scale: 5.0\n",
        "            width_scale: 5.0\n",
        "          }\n",
        "        }\n",
        "        matcher {\n",
        "          argmax_matcher {\n",
        "            matched_threshold: 0.5\n",
        "            unmatched_threshold: 0.5\n",
        "            ignore_thresholds: false\n",
        "            negatives_lower_than_unmatched: true\n",
        "            force_match_for_each_row: true\n",
        "            use_matmul_gather: true\n",
        "          }\n",
        "        }\n",
        "        similarity_calculator {\n",
        "          iou_similarity {\n",
        "          }\n",
        "        }\n",
        "        box_predictor {\n",
        "          convolutional_box_predictor {\n",
        "            conv_hyperparams {\n",
        "              regularizer {\n",
        "                l2_regularizer {\n",
        "                  weight: 3.99999989895e-05\n",
        "                }\n",
        "              }\n",
        "              initializer {\n",
        "                random_normal_initializer {\n",
        "                  mean: 0.0\n",
        "                  stddev: 0.00999999977648\n",
        "                }\n",
        "              }\n",
        "              activation: RELU_6\n",
        "              batch_norm {\n",
        "                decay: 0.97000002861\n",
        "                center: true\n",
        "                scale: true\n",
        "                epsilon: 0.0010000000475\n",
        "              }\n",
        "            }\n",
        "            min_depth: 0\n",
        "            max_depth: 0\n",
        "            num_layers_before_predictor: 0\n",
        "            use_dropout: false\n",
        "            dropout_keep_probability: 0.800000011921\n",
        "            kernel_size: 1\n",
        "            box_code_size: 4\n",
        "            apply_sigmoid_to_scores: false\n",
        "            class_prediction_bias_init: -4.59999990463\n",
        "          }\n",
        "        }\n",
        "        anchor_generator {\n",
        "          ssd_anchor_generator {\n",
        "            num_layers: 6\n",
        "            min_scale: 0.20000000298\n",
        "            max_scale: 0.949999988079\n",
        "            aspect_ratios: 1.0\n",
        "            aspect_ratios: 2.0\n",
        "            aspect_ratios: 0.5\n",
        "            aspect_ratios: 3.0\n",
        "            aspect_ratios: 0.333299994469\n",
        "          }\n",
        "        }\n",
        "        post_processing {\n",
        "          batch_non_max_suppression {\n",
        "            score_threshold: 0.300000011921\n",
        "            iou_threshold: 0.600000023842\n",
        "            max_detections_per_class: 100\n",
        "            max_total_detections: 100\n",
        "          }\n",
        "          score_converter: SIGMOID\n",
        "        }\n",
        "        normalize_loss_by_num_matches: true\n",
        "        loss {\n",
        "          localization_loss {\n",
        "            weighted_smooth_l1 {\n",
        "            }\n",
        "          }\n",
        "          classification_loss {\n",
        "            weighted_sigmoid_focal {\n",
        "              gamma: 2.0\n",
        "              alpha: 0.75\n",
        "            }\n",
        "          }\n",
        "          classification_weight: 1.0\n",
        "          localization_weight: 1.0\n",
        "        }\n",
        "        encode_background_as_zeros: true\n",
        "        normalize_loc_loss_by_codesize: true\n",
        "        inplace_batchnorm_update: true\n",
        "        freeze_batchnorm: false\n",
        "      }\n",
        "    }\n",
        "    train_config {\n",
        "      batch_size: 96\n",
        "      data_augmentation_options {\n",
        "        random_horizontal_flip {\n",
        "        }\n",
        "      }\n",
        "      data_augmentation_options {\n",
        "        ssd_random_crop {\n",
        "        }\n",
        "      }\n",
        "      sync_replicas: true\n",
        "      optimizer {\n",
        "        adam_optimizer: {\n",
        "          learning_rate: {\n",
        "            manual_step_learning_rate {\n",
        "              initial_learning_rate: .0002\n",
        "              schedule {\n",
        "                step: 500\n",
        "                learning_rate: .00003\n",
        "              }\n",
        "              schedule {\n",
        "                step: 1000\n",
        "                learning_rate: .000002\n",
        "              }\n",
        "              schedule {\n",
        "                step: 3000\n",
        "                learning_rate: .0000003\n",
        "              }\n",
        "              schedule {\n",
        "                step: 6000\n",
        "                learning_rate: .00000003\n",
        "              }\n",
        "            }\n",
        "          }\n",
        "        }\n",
        "        use_moving_average: false\n",
        "      }\n",
        "      fine_tune_checkpoint: \"ssd_mobilenet_v2_coco_2018_03_29/model.ckpt\"\n",
        "      from_detection_checkpoint: true\n",
        "      load_all_detection_checkpoint_vars: true\n",
        "      num_steps: 50000\n",
        "      startup_delay_steps: 0.0\n",
        "      replicas_to_aggregate: 8\n",
        "      max_number_of_boxes: 100\n",
        "      unpad_groundtruth_tensors: false\n",
        "      freeze_variables:\n",
        "            [ 'FeatureExtractor/MobilenetV2/Conv/',\n",
        "              'FeatureExtractor/MobilenetV2/expanded_conv/',\n",
        "              'FeatureExtractor/MobilenetV2/expanded_conv_1/',\n",
        "              'FeatureExtractor/MobilenetV2/expanded_conv_2/',\n",
        "              'FeatureExtractor/MobilenetV2/expanded_conv_3/',\n",
        "              'FeatureExtractor/MobilenetV2/expanded_conv_4/',\n",
        "              'FeatureExtractor/MobilenetV2/expanded_conv_5/',\n",
        "              'FeatureExtractor/MobilenetV2/expanded_conv_6/',\n",
        "              'FeatureExtractor/MobilenetV2/expanded_conv_7/']\n",
        "    }\n",
        "    train_input_reader {\n",
        "      label_map_path: \"data/wildlife.v1.tfrecord/animals_label_map.pbtxt\"\n",
        "      tf_record_input_reader {\n",
        "        input_path: \"data/wildlife.v1.tfrecord/animals_train.tfrecord\"\n",
        "      }\n",
        "    }\n",
        "    eval_config: {\n",
        "      num_examples: 750\n",
        "      num_visualizations: 50\n",
        "      eval_interval_secs: 0\n",
        "    }\n",
        "    eval_input_reader {\n",
        "      label_map_path: \"data/wildlife.v1.tfrecord/animals_label_map.pbtxt\"\n",
        "      shuffle: false\n",
        "      num_readers: 1\n",
        "      tf_record_input_reader {\n",
        "        input_path: \"data/wildlife.v1.tfrecord/animals_val.tfrecord\"\n",
        "      }\n",
        "    }\n",
        "    graph_rewriter {\n",
        "      quantization {\n",
        "        delay: 48000\n",
        "        weight_bits: 8\n",
        "        activation_bits: 8\n",
        "      }\n",
        "    }\n",
        "    ''')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeFny2auFrCJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://github.com/HanYangZhao/tf_wildlife_detector/releases/download/1/wildlife.v1.tfrecord.zip\n",
        "!unzip wildlife.v1.tfrecord.zip 'wildlife.v1.tfrecord/*' -d data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mX4HCgLKbnU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python legacy/train.py --logtostderr --train_dir=training/ --pipeline_config_path=ssd_mobilenet_v2_coco.config"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeCRQJxGLV6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python model_main.py \\\n",
        "  --pipeline_config_path=ssd_mobilenet_v2_coco.config\\\n",
        "  --model_dir=training/ \\\n",
        "  --num_train_steps=25000 \\\n",
        "  --num_eval_steps=200\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxchpRu-G3fo",
        "colab_type": "text"
      },
      "source": [
        "**TfLite conversion**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHzutuqKFPUd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python3 export_tflite_ssd_graph.py \\\n",
        "  --pipeline_config_path=\"ssd_mobilenet_v2_coco.config\" \\\n",
        "  --trained_checkpoint_prefix=\"training/model.ckpt-25000\" \\\n",
        "  --output_directory=\"training\" \\\n",
        "  --add_postprocessing_op=true"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oEObUmMFcj6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tflite_convert \\\n",
        "  --output_file=\"training/output_tflite_graph.tflite\" \\\n",
        "  --graph_def_file=\"training/tflite_graph.pb\" \\\n",
        "  --inference_type=QUANTIZED_UINT8 \\\n",
        "  --input_arrays=\"normalized_input_image_tensor\" \\\n",
        "  --output_arrays=\"TFLite_Detection_PostProcess,TFLite_Detection_PostProcess:1,TFLite_Detection_PostProcess:2,TFLite_Detection_PostProcess:3\" \\\n",
        "  --mean_values=128 \\\n",
        "  --std_dev_values=128 \\\n",
        "  --input_shapes=1,300,300,3 \\\n",
        "  --change_concat_input_ranges=false \\\n",
        "  --allow_nudging_weights_to_use_fast_gemm_kernel=true \\\n",
        "  --allow_custom_ops"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRKzDxzDdYg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
        "!echo \"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\" | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install edgetpu-compiler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXjn4UTAdhaT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/models/research/object_detection/training"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7kTQsLRdxbO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!edgetpu_compiler output_tflite_graph.tflite"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gb_e0zAKnKbY",
        "colab_type": "text"
      },
      "source": [
        "##EXporting inference graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYX4Ixm8DINT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python export_inference_graph.py --input_type image_tensor --pipeline_config_path ssd_mobilenet_v2_coco.config --trained_checkpoint_prefix training/model.ckpt-1255 --output_directory trained_inference_graph/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdKB9O17nUY_",
        "colab_type": "text"
      },
      "source": [
        "##ZIPPing the EXported graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdGuXwtkGDOR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip -r wildlife_graph.zip trained_inference_graph"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGC7imfbnaVB",
        "colab_type": "text"
      },
      "source": [
        "#LETS TEST OUR MODEL AND SEE RESULT\n",
        "\n",
        "> Copy about 9 images in the test_images folder and rename each to imagesX.jpg with X being a number from 1 to 9 before running the code below.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lltNtdzzEk1A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "\n",
        "from distutils.version import StrictVersion\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# This is needed since the notebook is stored in the object_detection folder.\n",
        "sys.path.append(\"..\")\n",
        "from object_detection.utils import ops as utils_ops\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "\n",
        "\n",
        "\n",
        "### Model preparation variable\n",
        "MODEL_NAME = 'trained_inference_graph'\n",
        "PATH_TO_FROZEN_GRAPH = MODEL_NAME + '/frozen_inference_graph.pb'\n",
        "PATH_TO_LABELS = 'data/animals_label_map.pbtxt'\n",
        "NUM_CLASSES = 15 #remember number of objects you are training? cool.\n",
        "\n",
        "\n",
        "### Load a (frozen) Tensorflow model into memory.\n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "  od_graph_def = tf.GraphDef()\n",
        "  with tf.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:\n",
        "    serialized_graph = fid.read()\n",
        "    od_graph_def.ParseFromString(serialized_graph)\n",
        "    tf.import_graph_def(od_graph_def, name='')\n",
        "\n",
        "\n",
        "###Loading label map\n",
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Load image into numpy function\n",
        "def load_image_into_numpy_array(image):\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "###STATING THE PATH TO IMAGES TO BE TESTED\n",
        "PATH_TO_TEST_IMAGES_DIR = 'test_images/'\n",
        "TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, 'image{}.jpg'.format(i)) for i in range(1, 4) ]\n",
        "IMAGE_SIZE = (12, 8)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Function to run inference on a single image which will later be used in an iteration\n",
        "def run_inference_for_single_image(image, graph):\n",
        "  with graph.as_default():\n",
        "    with tf.Session() as sess:\n",
        "      # Get handles to input and output tensors\n",
        "      ops = tf.get_default_graph().get_operations()\n",
        "      all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
        "      tensor_dict = {}\n",
        "      for key in [\n",
        "          'num_detections', 'detection_boxes', 'detection_scores',\n",
        "          'detection_classes', 'detection_masks'\n",
        "      ]:\n",
        "        tensor_name = key + ':0'\n",
        "        if tensor_name in all_tensor_names:\n",
        "          tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
        "              tensor_name)\n",
        "      if 'detection_masks' in tensor_dict:\n",
        "        # The following processing is only for single image\n",
        "        detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
        "        detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
        "        # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
        "        real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
        "        detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
        "        detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
        "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "            detection_masks, detection_boxes, image.shape[1], image.shape[2])\n",
        "        detection_masks_reframed = tf.cast(\n",
        "            tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
        "        # Follow the convention by adding back the batch dimension\n",
        "        tensor_dict['detection_masks'] = tf.expand_dims(\n",
        "            detection_masks_reframed, 0)\n",
        "      image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "      # Run inference\n",
        "      output_dict = sess.run(tensor_dict,\n",
        "                             feed_dict={image_tensor: image})\n",
        "\n",
        "      # all outputs are float32 numpy arrays, so convert types as appropriate\n",
        "      output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
        "      output_dict['detection_classes'] = output_dict[\n",
        "          'detection_classes'][0].astype(np.int64)\n",
        "      output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
        "      output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
        "      if 'detection_masks' in output_dict:\n",
        "        output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
        "  return output_dict\n",
        "\n",
        "\n",
        "\n",
        "### To iterate on each image in the test image path defined \n",
        "### NB define the range of numbers and let it match the number of imAGES IN TEST FOLDER +1\n",
        "for image_path in TEST_IMAGE_PATHS:\n",
        "  image = Image.open(image_path)\n",
        "  # the array based representation of the image will be used later in order to prepare the\n",
        "  # result image with boxes and labels on it.\n",
        "  image_np = load_image_into_numpy_array(image)\n",
        "  # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "  image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "  # Actual detection.\n",
        "  output_dict = run_inference_for_single_image(image_np_expanded, detection_graph)\n",
        "  # Visualization of the results of a detection.\n",
        "  vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np,\n",
        "      output_dict['detection_boxes'],\n",
        "      output_dict['detection_classes'],\n",
        "      output_dict['detection_scores'],\n",
        "      category_index,\n",
        "      instance_masks=output_dict.get('detection_masks'),\n",
        "      use_normalized_coordinates=True,\n",
        "      line_thickness=1)\n",
        "  display(Image.fromarray(image_np))\n",
        "  \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}